# Project Title

This Projects Goal is to use Amazon Web Service - Rekognition to analyze videos and retrieve facial landmark coordinates. With this coordinates we will analyze different emotions and try to connect specific facial landmark positions with emotions.

## Getting Started

These instructions will get you a copy of the project up and running on your local machine for development and testing purposes. See deployment for notes on how to deploy the project on a live system.

### Prerequisites

What things you need to install the software and how to install them

```
Give examples
```

### Installing

A step by step series of examples that tell you how to get a development env running

Say what the step will be

```
Give the example
```

And repeat

```
until finished
```

End with an example of getting some data out of the system or using it for a little demo

## Running the tests

Explain how to run the automated tests for this system

### Break down into end to end tests

Explain what these tests test and why

```
Give an example
```

### And coding style tests

Explain what these tests test and why

```
Give an example
```

## Deployment

Notes on how to deploy themselves

## Built With
*AWS Rekognition Services
*Anaconda IDE - Jupyter notebook
*Python

## Contributing

Please read [CONTRIBUTING.md](https://gist.github.com/PurpleBooth/b24679402957c63ec426) for details on our code of conduct, and the process for submitting pull requests to us.

## Versioning

Version 1

## Authors

* **Adam Bergstrom**
* **Peter Schaber**
* **Steven Livingstone** 

## License


## Acknowledgments


